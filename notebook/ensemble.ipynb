{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Experiment(Enum):\n",
    "    TREATMENT = 'treatent'\n",
    "    CONTROL = 'control'\n",
    "\n",
    "a = Experiment.TREATMENT\n",
    "# if a is not None:\n",
    "#     a.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'treatent'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "if a:\n",
    "    print('true')\n",
    "else:\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m run.prepare_data dir=local phase=$PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "EXP_NAME = 'exp083'\n",
    "RUN_NAMES = ['run0'] #, 'run1', 'run2', 'run3', 'run4']\n",
    "MODEL_NAME = 'best_model.pth' # best_model.pth or latest_model.pth\n",
    "SCORE_TH = 0.005\n",
    "DISTANCE = 40\n",
    "LOW_PASS_FILTER_HOUR = 3\n",
    "\n",
    "for run_name in RUN_NAMES:\n",
    "    command = [\n",
    "        'python',\n",
    "        '-m',\n",
    "        'run.inference',\n",
    "        'dir=local',\n",
    "        f'+experiment={EXP_NAME}',\n",
    "        f'weight.run_name={run_name}',\n",
    "        'batch_size=64',\n",
    "        f'post_process.score_th={SCORE_TH}',\n",
    "        f'post_process.distance={DISTANCE}',\n",
    "        f'post_process.low_pass_filter_hour={LOW_PASS_FILTER_HOUR}',\n",
    "        f'phase={PHASE}',\n",
    "    ]\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'exp085'\n",
    "\n",
    "for run_name in RUN_NAMES:\n",
    "    command = [\n",
    "        'python',\n",
    "        '-m',\n",
    "        'run.inference',\n",
    "        'dir=local',\n",
    "        f'+experiment={EXP_NAME}',\n",
    "        f'weight.run_name={run_name}',\n",
    "        'batch_size=64',\n",
    "        f'post_process.score_th={SCORE_TH}',\n",
    "        f'post_process.distance={DISTANCE}',\n",
    "        f'post_process.low_pass_filter_hour={LOW_PASS_FILTER_HOUR}',\n",
    "        f'phase={PHASE}',\n",
    "    ]\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds_list = []\n",
    "EXP_NAME = 'exp083'\n",
    "for run_name in RUN_NAMES:\n",
    "    preds = np.load(f\"../output/inference/{EXP_NAME}/{run_name}/preds.npy\")\n",
    "    preds_list.append(preds)\n",
    "keys1 = np.load(f\"../output/inference/{EXP_NAME}/{run_name}/keys.npy\")\n",
    "\n",
    "preds1 = np.zeros(preds_list[0].shape)\n",
    "for i in range(len(RUN_NAMES)):\n",
    "    preds1 += preds_list[i]\n",
    "# 単純な平均を取る\n",
    "preds1 /= len(RUN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "EXP_NAME = 'exp085'\n",
    "for run_name in RUN_NAMES:\n",
    "    preds = np.load(f\"../output/inference/{EXP_NAME}/{run_name}/preds.npy\")\n",
    "    preds_list.append(preds)\n",
    "keys2 = np.load(f\"../output/inference/{EXP_NAME}/{run_name}/keys.npy\")\n",
    "\n",
    "preds2 = np.zeros(preds_list[0].shape)\n",
    "for i in range(len(RUN_NAMES)):\n",
    "    preds2 += preds_list[i]\n",
    "# 単純な平均を取る\n",
    "preds2 /= len(RUN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gt_df = pd.read_csv(\"../data/child-mind-institute-detect-sleep-states/train_events.csv\")\n",
    "gt_df = gt_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run.inference import make_submission\n",
    "from src.utils.metrics import event_detection_ap\n",
    "\n",
    "sub_df = make_submission(keys1, preds1, SCORE_TH,DISTANCE, LOW_PASS_FILTER_HOUR)\n",
    "score = event_detection_ap(gt_df, sub_df.to_pandas())\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = make_submission(keys2, preds2, SCORE_TH,DISTANCE, LOW_PASS_FILTER_HOUR)\n",
    "score = event_detection_ap(gt_df, sub_df.to_pandas())\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = preds2.shape[2]\n",
    "chunk_size = preds2.shape[1]\n",
    "\n",
    "series_ids1 = np.array(list(map(lambda x: x.split(\"_\")[0], keys1)))\n",
    "series_ids2 = np.array(list(map(lambda x: x.split(\"_\")[0], keys2)))\n",
    "unique_series_ids = np.unique(series_ids1)\n",
    "preds_list = []\n",
    "max_length = 0\n",
    "for series_id in unique_series_ids:\n",
    "    series_idx1 = np.where(series_ids1 == series_id)[0]\n",
    "    series_idx2 = np.where(series_ids2 == series_id)[0]\n",
    "    series_preds1 = preds1[series_idx1].reshape(-1, n_classes)\n",
    "    series_preds2 = preds2[series_idx2].reshape(-1, n_classes)\n",
    "    min_duration = min(len(series_preds1), len(series_preds2))\n",
    "    series_preds1 = series_preds1[:min_duration]\n",
    "    series_preds2 = series_preds2[:min_duration]\n",
    "\n",
    "    series_preds = series_preds1 * 0.5 + series_preds2 * 0.5\n",
    "    preds_list.append(series_preds)\n",
    "    max_length = max(max_length, len(series_preds))\n",
    "\n",
    "# Pad each element to the maximum length\n",
    "padded_preds_list = [np.pad(x, ((0, max_length - x.shape[0]), (0, 0)), 'constant', constant_values=0) for x in preds_list]\n",
    "preds = np.stack(padded_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = unique_series_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run.inference import make_submission\n",
    "\n",
    "sub_df = make_submission(keys, preds, SCORE_TH,DISTANCE, LOW_PASS_FILTER_HOUR)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import event_detection_ap\n",
    "\n",
    "score = event_detection_ap(gt_df, sub_df.to_pandas())\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
